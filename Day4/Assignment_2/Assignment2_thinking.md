# Assignment2 の考え方

## 課題内容
find_most_popular_pages() 関数を書いて、ページランクを計算して重要度の高いページトップ 10 を求めてください
このスライドで「言葉で説明したアルゴリズムを自分で具体化してコードに落とす」のが宿題の意図です
50 行程度で書けます 😀

## 考え方
### ページランクのアイデア
1. たくさんのノードから参照されているほど大きい
2. ランクの大きいものから参照されているほど大きい
3. リンク数の少ないノードから参照されているほど大きい

### アルゴリズム
- assignment2.py
参照先以外のノードにのみそのノードのランク*0.15を振り分ける

1. すべてのノードに初期値1.0を与える
2. (そのノードのランク/エッジの数)*0.85を参照先のノードに振り分ける
3. (そのノードのランク/参照先以外のノード数)*0.15を参照先以外のノードに振り分ける
4. すべてのノードに対して2-3を繰り返す
5. 各ノードについて、ランクを受け取ったランクの合計に変更する
6. 収束するまで2-5を繰り返す
    1. 収束の条件：∑(新しいランク[i] - 元々のランク[i])^2 <= 0.02

- assignment2-1.py
1. すべてのノードに初期値1.0を与える
すべてのノードにそのノードのランク*0.15を振り分ける

2. (そのノードのランク/エッジの数)*0.85を参照先のノードに振り分ける
3. (そのノードのランク)*0.15を保存する → 最後に振りわける
4. すべてのノードに対して2-3を繰り返す
5. 各ノードについて、すべてに振り分けられるランクの合計値を平等に振り分ける (ノード数で割ったものを振り分ける)
6. 各ノードについて、ランクを受け取ったランクの合計に変更する
7. 収束するまで2-6を繰り返す
    1. 収束の条件：∑(新しいランク[i] - 元々のランク[i])^2 <= 0.02

## further thoughts
1. 
assignment2.pyは毎ループでそれぞれの参照外のノードにふりわけないといけない。
このとき、参照先のノード数は高々数千、万程度であるが、参照外のノード数は(すべてのノード数) - (参照先のノード数)のため、数十万、百万に及ぶ。
そんため、参照以外のノードに振り分ける時間が平均して0.03秒ほどかかり(← 実装結果より)、それをノード数分ループさせるとなると、
1回全ノードにランクを振り分けるのに数十時間かかってしまう。

一方、assignment2-1.pyはすべてのノードに対して振り分けるため、各ノードがどのノードを参照していないか確認する必要がないため、
(各ノードのランク)* (0.15)を加算し,保存しておけば、ループの最後に全ノード数で割った分を平等に振り分けるだけで済む。

よって実行時間の観点で、assignment2-1.pyで実装する方が良いと考えた。

2. 
1ではassignment2-1.pyで実装する方がいいと述べたが、実際にassignment2-1.pyを実行すると収束するまでに2,3時間ほどかかってしまった。
そのため、比較的assignment2-1.pyの方法で実装するのがいいだけで、さらにいいアルゴリズムがあるのではと考えている。

[googleのpagerankアルゴリズム](https://ahrefs.com/blog/google-pagerank/)
実際にgoogleでも同じようなアルゴリズムが使われている.
加えて、今回実装したアルゴリズムでは完全一致でなく収束として考えているため、今のアルゴリズムが限界なのかなとも思った。
